import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from sklearn.preprocessing import MinMaxScaler
from keras.models import Sequential
from keras.layers import LSTM, Dense

# from subprocess import check_output
# print check_output(['ls', '../ConEdison']).decode('utf8')

import warnings
warnings.filterwarnings('ignore')
from time import time

start = time()
# ==========Initial trade parameters =============
symbol = 'BTC/USD'
timeframe = '1d'
since = '2017-01-01 00:00:00'

header = ['Timestamp', 'Open', 'High', 'Low', 'Close', 'Volume']

# ==========Initial exchange parameters =============
# kraken = exchange_data('kraken', 'BTC/USD', timeframe=timeframe, since=hist_start_date)
# write_to_csv(kraken,'BTC/USD','kraken')

# data = pd.DataFrame(kraken, columns=header)
# print(data.head())
data = pd.read_csv("gemini_BTCUSD_2018_1min.csv")
print data['Close'].shape[0]
# train_data = data['Close'][:11000]
# test_data = data['Close'][11000:]
# Scale data to be between 0 and 1
# Remember normalise test and training data wrt to training data
scl = MinMaxScaler()

'''
train_data =  train_data.reshape(-1, 1)
test_data = train_data.reshape(-1, 1)

# reshape both train and test data

train_data = train_data.reshape(-1)

# Normalise test data
test_data = scaler.transform(test_data).reshape(-1)
'''

# Scale the data
cl = data['Close'].values.reshape(data['Close'].shape[0],1)
cl = scl.fit_transform(cl)

# Create a function to process the data into N day lookback slioes
def processData(data, lookback, predict_period):
    X, Y = [], []
    for i in range(len(data)-lookback - predict_period - 1):
        X.append(data[i:(i+lookback),0])
        Y.append(data[i+lookback:(i+lookback+predict_period),0])
    return np.array(X), np.array(Y)

# LSTM Model - 5 essential components
# Cell State - this represents the internal memory of the cell
# which stores both short term as well as long term

# hidden state - This is output state information calculated wrt
# current input, previous hidden state and current cell input

# input gate - decides how much infomation from the ccurrent input flows to cell state

# Forget state - decides how much information flows from the current input and previous
# cell state

# output gate

def model_building(n_layers, n_epochs, lookback):
    model = Sequential
    model.add(LSTM(n_layers, input_shape=(lookback,1)))
    model.add(Dense(1))
    model.compile(optimizer='adam',loss='mse')
    return model

n_layers = 100
n_epochs = 300
lookback = 50
predict_period = 20
X,Y = processData(cl, lookback=lookback, predict_period=predict_period)

X_train,X_test = X[:int(X.shape[0]*0.8)], X[int(X.shape[0]*0.8):]
Y_train,Y_test = Y[:int(Y.shape[0]*0.80)],Y[int(Y.shape[0]*0.80):]

# reshape data for (Sample, Timestamp, Features)
X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], lookback)
X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], lookback)

# Fit model and check for over-fitting
model = model_building(n_layers, n_epochs, lookback)
history = model.fit(X_train,Y_train,epochs=n_epochs,
                    validation_data=(X_test,Y_test),
                    shuffle=False)

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])

Xt = model.predict(X_test)
plt.plot(scl.inverse_transform(Xt))
plt.plot(scl.inverse_transform(Y_test.reshape(-1,1)))

actual = []
predicted = []
i = 249
Xt = model.predict(X_test[i].reshape(1, 7, 1))

print('Predicted:{0}, Actual:{1}'.format(scl.inverse_transform(Xt),
                                         scl.inverse_transform(Y_test[i].reshape(-1,1))))

predicted.append(scl.inverse_transform(Xt))
actual.append(scl.inverse_transform(Y_test[i].reshape(-1,1)))

result_df = pd.DataFrame({'Predicted':list(np.reshape(predicted,-1)),
                          'Actual':list(np.reshape(actual,-1))})







